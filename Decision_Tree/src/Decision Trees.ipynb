{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from read_data import *\n",
    "from node import Node\n",
    "import heapq\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_mispred(pred,lab):\n",
    "    return (len(pred) - np.count_nonzero(pred==lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_build_accuracy(root,tree,levels,level_size,train,val,test):\n",
    "    full_data = [train,val,test]\n",
    "    result = np.zeros((len(levels)+1,4),dtype=np.int32)\n",
    "    for i in range(len(full_data)):\n",
    "        data = full_data[i]\n",
    "        label = data[:,0]\n",
    "        pred = root.predict(data)\n",
    "        mispred = num_mispred(pred,label)\n",
    "        for lvl in range(len(levels)):\n",
    "            result[lvl][0] = level_size[lvl]\n",
    "            new_mispred = mispred - sum([tree[idx].gain_prune for idx in levels[lvl]])\n",
    "            result[lvl][i+1] = new_mispred\n",
    "        result[-1][0] = len(tree)\n",
    "        result[-1][i+1] = mispred\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune(root,train,val,test):\n",
    "    result = []\n",
    "    train_label = train[:,0]\n",
    "    val_label = val[:,0]\n",
    "    test_label = test[:,0]\n",
    "    nodes = root.get_subtree()\n",
    "    while True:\n",
    "        train_misc = num_mispred(root.predict(train),train_label)\n",
    "        test_misc = num_mispred(root.predict(test),test_label)\n",
    "        val_misc = num_mispred(root.predict(val),val_label) #important val should be last\n",
    "        result.append([len(nodes),train_misc,val_misc,test_misc])\n",
    "        prune_node = None\n",
    "        prune_gain = -1\n",
    "        \n",
    "        for node in nodes:\n",
    "            if ((not(node.isLeafNode)) and (node.gain_prune > prune_gain)):\n",
    "                prune_node=node\n",
    "                prune_gain = node.gain_prune\n",
    "        if prune_node==None:\n",
    "            break\n",
    "        prune_node.isLeafNode = True\n",
    "        nodes = root.get_subtree()\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(misc,train,val,test,invert=False,title=None,path=None):\n",
    "    divider = np.array([len(train),len(val),len(test)])\n",
    "    accuracy =  (1 - misc[:,1:]/divider)\n",
    "    num_nodes = misc[:,0]\n",
    "    plt.plot(num_nodes,accuracy[:,0],label=\"train\")\n",
    "    plt.plot(num_nodes,accuracy[:,1],label=\"val\")\n",
    "    plt.plot(num_nodes,accuracy[:,2],label=\"test\")\n",
    "    plt.legend(loc='upper left', frameon=False)\n",
    "    plt.xlabel(\"Number of Nodes\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    if invert:\n",
    "        plt.gca().invert_xaxis()\n",
    "    if path:\n",
    "        plt.savefig(path,format=\"pdf\",bbox_inches='tight')\n",
    "    plt.show()\n",
    "    return (num_nodes,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN=\"../dataset/train.csv\"\n",
    "TEST=\"../dataset/test.csv\"\n",
    "VAL=\"../dataset/valid.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../dataset/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-91e714a4cd8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbinarize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# binarize=True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_dta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbinarize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_dta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbinarize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_dta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVAL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbinarize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/src/read_data.py\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(file, binarize)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \"\"\"\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# Calculate the medians\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0magem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfnlwgtm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medunm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcapgm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcaplm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhpwm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmedians\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0mfin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/src/read_data.py\u001b[0m in \u001b[0;36mmedians\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mmedian\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcategorical\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \"\"\"\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mfin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfnlwgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhpw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../dataset/train.csv'"
     ]
    }
   ],
   "source": [
    "binarize=False\n",
    "# binarize=True\n",
    "train_dta = preprocess(TRAIN,binarize)\n",
    "test_dta = preprocess(TEST,binarize)\n",
    "val_dta = preprocess(VAL,binarize)\n",
    "# train_dta = train_dta[np.where(train_dta[:,0]==0)]\n",
    "testlabels = test_dta[:,0]\n",
    "trainlabels = train_dta[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = []\n",
    "leaves = []\n",
    "levels = []\n",
    "level_size = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if binarize:\n",
    "    root = Node(train_dta,set())\n",
    "else:\n",
    "    root = Node(train_dta,set([1,3,5,11,12,13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.append(root)\n",
    "heapq.heappush(leaves,(-root.info_gain,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(leaves)!=0 :\n",
    "    iteration+=1\n",
    "    # indices of leaves at this iteration\n",
    "    level = [x[1] for x in leaves]\n",
    "    # size of tree at this level\n",
    "    size = len(tree)\n",
    "    neggain,idx = heapq.heappop(leaves)\n",
    "    new_leaves = tree[idx].grow_tree()\n",
    "    if(len(new_leaves)>0):\n",
    "        levels.append(level)\n",
    "        level_size.append(size)\n",
    "    for l in new_leaves:\n",
    "        newidx = len(tree)\n",
    "        tree.append(l)\n",
    "        heapq.heappush(leaves,(-l.info_gain,newidx))\n",
    "#     print(len(tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multi_split(node):\n",
    "    if node.isLeafNode:\n",
    "        return {}\n",
    "    result = {}\n",
    "    for child in node.children:\n",
    "        res = get_multi_split(node.children[child])\n",
    "        for key in res.keys():\n",
    "            prev_val = result.get(key,[])\n",
    "            if(len(prev_val) < len(res[key])):\n",
    "                result[key] = res[key]\n",
    "    result[node.split_attr] = result.get(node.split_attr,[])+[node.split_val]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_numerical_splits = get_multi_split(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_numerical_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_misc = get_build_accuracy(root,tree,levels,level_size,train_dta,val_dta,test_dta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if binarize:\n",
    "    title = \"Nodes VS Accuracy [Binary]\"\n",
    "    path = \"../plots/grow_binary.pdf\"\n",
    "else:\n",
    "    title = \"Nodes VS Accuracy [Numerical]\"\n",
    "    path = \"../plots/grow_numerical.pdf\"\n",
    "# build_numnodes,build_accuracy = plot(build_misc,train_dta,val_dta,test_dta,invert=False,title=title,path=path)\n",
    "build_numnodes,build_accuracy = plot(build_misc,train_dta,val_dta,test_dta,invert=False,title=title)\n",
    "print(\"Max accuracy:\\nTrain: {}\\nVal: {}\\nTest: {}\\n\".format(*np.max(build_accuracy,axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prune_misc = prune(root,train_dta,val_dta,test_dta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if binarize:\n",
    "    title = \"Nodes VS Accuracy [Binary Pruning]\"\n",
    "    path = \"../plots/prune_binary.pdf\"\n",
    "else:\n",
    "    title = \"Nodes VS Accuracy [Numerical Pruning]\"\n",
    "    path = \"../plots/prune_numerical.pdf\"\n",
    "# prune_numnodes,prune_accuracy = plot(prune_misc,train_dta,val_dta,test_dta,invert=True,title=title,path=path)\n",
    "prune_numnodes,prune_accuracy = plot(prune_misc,train_dta,val_dta,test_dta,invert=True,title=title)\n",
    "print(\"Max accuracy:\\nTrain: {}\\nVal: {}\\nTest: {}\\n\".format(*np.max(prune_accuracy,axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(max_depth,min_samples_split,min_samples_leaf,train,val,test):\n",
    "    clf = DTC(criterion=\"entropy\",max_depth=max_depth,min_samples_split=min_samples_split,min_samples_leaf=min_samples_leaf)\n",
    "    clf.fit(train_dta[:,1:],train_dta[:,0])\n",
    "    train_pred = clf.predict(train[:,1:])\n",
    "    val_pred = clf.predict(val[:,1:])\n",
    "    test_pred = clf.predict(test[:,1:])\n",
    "    train_acc = np.mean(train_pred==train[:,0])\n",
    "    val_acc = np.mean(val_pred==val[:,0])\n",
    "    test_acc = np.mean(test_pred==test[:,0])\n",
    "    print(\"max_depth: {} , min_samples_split: {}, min_samples_lead: {}\".format(max_depth,min_samples_split,min_samples_leaf))\n",
    "    print(\"Train Acc: {}\\nVal Acc: {}\\nTest Acc: {}\".format(train_acc,val_acc,test_acc))\n",
    "    print(\"{},{},{},{},{},{}\".format(max_depth,min_samples_split,min_samples_leaf,train_acc,val_acc,test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(1,\t2,\t1,train_dta,val_dta,test_dta)\n",
    "get_accuracy(2,\t2,\t1,train_dta,val_dta,test_dta)\n",
    "get_accuracy(5,\t2,\t1,train_dta,val_dta,test_dta)\n",
    "get_accuracy(7,\t2,\t1,train_dta,val_dta,test_dta)\n",
    "get_accuracy(10,\t2,\t1,train_dta,val_dta,test_dta)\n",
    "get_accuracy(15,\t2,\t1,train_dta,val_dta,test_dta)\n",
    "get_accuracy(10,\t4,\t1,train_dta,val_dta,test_dta)\n",
    "get_accuracy(10,\t7,\t1,train_dta,val_dta,test_dta)\n",
    "get_accuracy(10,\t10,\t1,train_dta,val_dta,test_dta)\n",
    "get_accuracy(10,\t20,\t1,train_dta,val_dta,test_dta)\n",
    "get_accuracy(10,\t7,\t2,train_dta,val_dta,test_dta)\n",
    "get_accuracy(10,\t7,\t4,train_dta,val_dta,test_dta)\n",
    "get_accuracy(10,\t10,\t4,train_dta,val_dta,test_dta)\n",
    "get_accuracy(10,\t10,\t10,train_dta,val_dta,test_dta)\n",
    "get_accuracy(10,\t10,\t15,train_dta,val_dta,test_dta)\n",
    "get_accuracy(10,\t10,\t20,train_dta,val_dta,test_dta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(10,\t4,\t10,train_dta,val_dta,test_dta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rfc_accuracy(n_estimators,max_features,bootstrap,train,val,test):\n",
    "    clf = RFC(criterion=\"entropy\",n_estimators=n_estimators,max_features=max_features,bootstrap=bootstrap)\n",
    "    clf.fit(train_dta[:,1:],train_dta[:,0])\n",
    "    train_pred = clf.predict(train[:,1:])\n",
    "    val_pred = clf.predict(val[:,1:])\n",
    "    test_pred = clf.predict(test[:,1:])\n",
    "    train_acc = np.mean(train_pred==train[:,0])\n",
    "    val_acc = np.mean(val_pred==val[:,0])\n",
    "    test_acc = np.mean(test_pred==test[:,0])\n",
    "    print(\"n_estimators: {} ,max_features: {} ,bootstrap: {}\".format(n_estimators,max_features,bootstrap))\n",
    "    print(\"Train Acc: {}\\nVal Acc: {}\\nTest Acc: {}\".format(train_acc,val_acc,test_acc))\n",
    "    print(\"{},{},{},{},{},{}\".format(n_estimators,max_features,bootstrap,train_acc,val_acc,test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_rfc_accuracy(30,4,True,train_dta,val_dta,test_dta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(train_dta[:,1:],train_dta[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(test_dta[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(pred==test_dta[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
